services:
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile
    #image: apache/airflow:2.7.1
    container_name: airflow-init
    #command: bash -c "airflow db init"
    command: bash -c "pip install streamlit && airflow db migrate && airflow users create \
      --username airflow \
      --password airflow \
      --firstname airflow \
      --lastname airflow \
      --role Admin \
      --email admin@example.com"
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../movie_data:/opt/movie_data

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    #image: apache/airflow:2.7.1
    container_name: airflow-webserver
    depends_on:
      - airflow-init
      - airflow-scheduler
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
      - DUCKDB_PATH=/mnt/streamlit/star_schema.db
    ports:
      - "8081:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../star_schema.db:/star_schema.db
      - ../movie_data:/opt/movie_data
    #command: ["airflow", "webserver"]
    command: bash -c "pip install streamlit && airflow webserver"

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    #image: apache/airflow:2.7.1
    container_name: airflow-scheduler
    depends_on:
      - airflow-init
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
      - DUCKDB_PATH=/mnt/streamlit/star_schema.db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../star_schema.db:/star_schema.db
      - ../movie_data:/opt/movie_data
    command: ["airflow", "scheduler"]

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:6.2
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: [ "redis-server", "--appendonly", "yes" ]

  duckdb:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: duckdb
    depends_on:
      - airflow-init
      - postgres
      - redis
    environment:
      - DUCKDB_PATH=/mnt/streamlit/star_schema.db

    volumes:
      - ../star_schema.db:/star_schema.db
      - ../movie_data:/opt/movie_data
    command: bash -c "pip install streamlit && airflow webserver"
    stdin_open: true
    tty: true

  streamlit:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: streamlit
    depends_on:
      - airflow-init
      - airflow-webserver
    ports:
      - "8501:8501"
    volumes:
      #- ../main.py:/opt/airflow/dags/streamlit/main.py
      - ../streamlit:/opt/airflow/dags/streamlit
      - duckdb_data:/mnt/streamlit
    environment:
      - AIRFLOW_CONN_DUCKDB=duckdb:///mnt/streamlit/star_schema.db

    command: bash -c "pip install streamlit && pwd && cd dags && pwd && cd streamlit && pwd && streamlit run main.py && airflow webserver"
    #command: ["streamlit", "run", "/opt/airflow/dags/streamlit/main.py"]


  airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile
    #image: apache/airflow:2.7.1
    container_name: airflow-worker
    depends_on:
      - airflow-scheduler
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
      - DUCKDB_PATH=/mnt/streamlit/star_schema.db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../star_schema.db:/star_schema.db
      - ../movie_data:/opt/movie_data
    command: ["airflow", "celery", "worker"]

volumes:
  postgres_data:
  airflow_logs:
  airflow_dags:
  airflow_plugins:
  redis_data:
  duckdb_data:
  streamlit_data:
